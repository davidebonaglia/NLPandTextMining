{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Selection and Dimension Reduction\n",
    "\n",
    "Data: **BBC NEWS** - the data set consist of 2,225 documents divided into 5 categories:\n",
    "- business\n",
    "- entertainment\n",
    "- politics\n",
    "- sport\n",
    "- tech\n",
    "\n",
    "D. Greene and P. Cunningham. \"Practical Solutions to the Problem of Diagonal Dominance in Kernel Document Clustering\", Proc. ICML 2006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chris Evans back on the market\\n\\nBroadcaster ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Giggs handed Wales leading role\\n\\nRyan Giggs ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wales silent on Grand Slam talk\\n\\nRhys Willia...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenya lift Chepkemei's suspension\\n\\nKenya's a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lee to create new film superhero\\n\\nComic book...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>Tory leader quits legal position\\n\\nDavid McLe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Buyers snap up Jet Airways' shares\\n\\nInvestor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Wright-Phillips to start on right\\n\\nEngland c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>Google's toolbar sparks concern\\n\\nSearch engi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>WMC profits up amid bid criticism\\n\\nAustralia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Chris Evans back on the market\\n\\nBroadcaster ...      1\n",
       "1     Giggs handed Wales leading role\\n\\nRyan Giggs ...      3\n",
       "2     Wales silent on Grand Slam talk\\n\\nRhys Willia...      3\n",
       "3     Kenya lift Chepkemei's suspension\\n\\nKenya's a...      3\n",
       "4     Lee to create new film superhero\\n\\nComic book...      1\n",
       "...                                                 ...    ...\n",
       "2220  Tory leader quits legal position\\n\\nDavid McLe...      2\n",
       "2221  Buyers snap up Jet Airways' shares\\n\\nInvestor...      0\n",
       "2222  Wright-Phillips to start on right\\n\\nEngland c...      3\n",
       "2223  Google's toolbar sparks concern\\n\\nSearch engi...      4\n",
       "2224  WMC profits up amid bid criticism\\n\\nAustralia...      0\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = 321 \n",
    "#The random_state parameter ensures that the data is shuffled in a reproducible way if it's set to a fixed number.\n",
    "\n",
    "DATA_DIR = \"/Users/davidebonaglia/Dropbox/PhD NOTES/COURSES/Utretch Summer School/Tuesday/bbc\"\n",
    "\n",
    "data = load_files(DATA_DIR, encoding=\"utf-8\", decode_error=\"replace\", random_state=random_state)\n",
    "df = pd.DataFrame(list(zip(data['data'], data['target'])), columns=['text', 'label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the unique target names in your data and check the number of articles in each category. \n",
    "Then split your data into training (80%) and test (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(df['label'], return_counts=True) \n",
    "#np.unique(data.target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[510 386 417 511 401]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels)\n",
    "print(counts)\n",
    "\n",
    "#name of the labels\n",
    "data.target_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business': 510, 'entertainment': 386, 'politics': 417, 'sport': 511, 'tech': 401}\n"
     ]
    }
   ],
   "source": [
    "print(dict(zip(data.target_names, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into training and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the CountVectorizer from sklearn and convert the text data into a document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780, 23908)\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer to remove unwanted elements from out data like symbols\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's bag of words tool.\n",
    "# In case of memory issues, reduce the max_features value\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True,\n",
    "                             tokenizer=None,\n",
    "                             stop_words='english',\n",
    "                             ngram_range=(1, 2),\n",
    "                             analyzer='word',\n",
    "                             min_df=3,\n",
    "                             max_features=None)\n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model and learns the vocabulary; \n",
    "# second, it transforms our data into feature vectors. \n",
    "# The input to fit_transform should be a list of strings.\n",
    "\n",
    "bbc_dtm = vectorizer.fit_transform(X_train)\n",
    "print(bbc_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between CountVectorizer and tfidfVectorizer?\n",
    "The only difference is that the TfidfVectorizer() returns floats while the CountVectorizer() returns ints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print top 20 frequent words in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['said', 'mr', 'year', 'people', 'new', 'time', 'world',\n",
       "       'government', 'uk', 'years', 'best', 'just', 'told', 'film',\n",
       "       'make', 'game', 'like', 'music', 'labour', '000'], dtype='<U27')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = np.argsort(np.asarray(bbc_dtm.sum(axis=0)).ravel())[::-1]\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "feature_names[importance[:20]]\n",
    "\n",
    "#[::-1] takes the reverse: a=1234 --> a[::-1]=4321 --> list[<start>:<stop>:<step>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', 'deco', 'olympic bronze', ..., 'public', 'says',\n",
       "       'government'], dtype='<U27')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# less used words\n",
    "feature_names_2 = np.array(vectorizer.get_feature_names())\n",
    "feature_names_2[importance[::-20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1770</th>\n",
       "      <th>1771</th>\n",
       "      <th>1772</th>\n",
       "      <th>1773</th>\n",
       "      <th>1774</th>\n",
       "      <th>1775</th>\n",
       "      <th>1776</th>\n",
       "      <th>1777</th>\n",
       "      <th>1778</th>\n",
       "      <th>1779</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>retailers</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>figures</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retail</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>december</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christmas</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ons</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank england</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1780 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "retailers        0     0     7     0     0     0     0     0     0     0  ...   \n",
       "figures          0     0     7     0     0     0     0     1     0     0  ...   \n",
       "sales            0     0     6     0     0     0     0     0     0     1  ...   \n",
       "retail           0     0     6     0     0     0     0     0     0     0  ...   \n",
       "december         0     0     5     0     0     1     1     0     0     0  ...   \n",
       "christmas        0     0     5     0     0     0     0     0     0     0  ...   \n",
       "ons              0     0     4     0     0     0     0     0     0     0  ...   \n",
       "worst            0     0     4     0     0     0     0     0     0     0  ...   \n",
       "said             6     3     4     2     0     8     2     2     0     4  ...   \n",
       "bank england     0     0     3     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "              1770  1771  1772  1773  1774  1775  1776  1777  1778  1779  \n",
       "retailers        0     0     0     0     0     0     0     0     0     0  \n",
       "figures          0     0     0     0     2     0     0     0     0     0  \n",
       "sales            0     0     0     4     0     0     0     0     0     0  \n",
       "retail           0     0     0     0     0     0     0     0     0     0  \n",
       "december         0     0     0     1     0     0     0     1     0     0  \n",
       "christmas        0     0     0     0     0     0     0     0     0     0  \n",
       "ons              0     0     0     0     0     0     0     0     0     0  \n",
       "worst            0     0     0     0     0     0     0     0     0     0  \n",
       "said             3     6     0     5     5     3     2     4     1     1  \n",
       "bank england     0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[10 rows x 1780 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You can also sort the counts based on a document:\n",
    "\n",
    "counts = pd.DataFrame(bbc_dtm.toarray(),\n",
    "                      columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Show us the top 10 most common words in document 2\n",
    "counts.T.sort_values(by=2, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter-based feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the feature selection library in sklearn load the SelectKBest function  and apply it on the BBC dataset using the **chi-squared** method. \n",
    "Extract top 20 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1780x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4428 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch2 = SelectKBest(chi2, k=20)\n",
    "ch2.fit_transform(bbc_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_chi = [feature_names[i] for i in ch2.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best',\n",
       " 'blair',\n",
       " 'brown',\n",
       " 'computer',\n",
       " 'digital',\n",
       " 'election',\n",
       " 'film',\n",
       " 'government',\n",
       " 'labour',\n",
       " 'minister',\n",
       " 'mobile',\n",
       " 'mr',\n",
       " 'mr blair',\n",
       " 'music',\n",
       " 'net',\n",
       " 'party',\n",
       " 'people',\n",
       " 'software',\n",
       " 'technology',\n",
       " 'users']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the 20 top features according to the **mutual** information feature selection method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1780x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6350 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_info = SelectKBest(mutual_info_classif, k=20)\n",
    "mutual_info.fit_transform(bbc_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blair',\n",
       " 'coach',\n",
       " 'election',\n",
       " 'film',\n",
       " 'firm',\n",
       " 'game',\n",
       " 'government',\n",
       " 'labour',\n",
       " 'market',\n",
       " 'minister',\n",
       " 'mr',\n",
       " 'music',\n",
       " 'party',\n",
       " 'people',\n",
       " 'said',\n",
       " 'secretary',\n",
       " 'technology',\n",
       " 'tory',\n",
       " 'users',\n",
       " 'win']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_mutual_info = [feature_names[i] for i in mutual_info.get_support(indices=True)]\n",
    "feature_names_mutual_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the functions for embedded feature selection is the SelectFromModel function in sklearn. \n",
    "Use this function with L1 norm SVM and check how many non-zero coefficients left in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the matrix before applying the embedded feature selection: (1780, 23908)\n",
      "shape of the matrix before applying the embedded feature selection: (1780, 156)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the matrix before applying the embedded feature selection:\", bbc_dtm.shape)\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
    "model = SelectFromModel(lsvc).fit(bbc_dtm, y_train) #add threshold=0.18 as another argument to select features that have an importance of more than 0.18\n",
    "X_new = model.transform(bbc_dtm)\n",
    "print(\"shape of the matrix before applying the embedded feature selection:\", X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LinearSVC(C=0.01, dual=False, penalty='l1'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        , -0.08072364,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check the values\n",
    "model.estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the top features according to the SVM model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False, False, False])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by SelectFromModel:  ['000' '2004' 'airlines' 'album' 'analysts' 'apple' 'arsenal' 'athens'\n",
      " 'athletics' 'award' 'ballet' 'ban' 'band' 'bank' 'bbc' 'best' 'bid'\n",
      " 'blair' 'blog' 'book' 'britain' 'british' 'broadband' 'brown' 'business'\n",
      " 'champion' 'chart' 'chelsea' 'chief' 'children' 'china' 'club' 'coach'\n",
      " 'comedy' 'committee' 'companies' 'company' 'computer' 'content' 'council'\n",
      " 'countries' 'cup' 'data' 'deal' 'deutsche' 'digital' 'dollar' 'doping'\n",
      " 'drugs' 'economic' 'economy' 'education' 'election' 'england' 'european'\n",
      " 'euros' 'film' 'final' 'financial' 'firm' 'firms' 'fraud' 'game' 'games'\n",
      " 'gaming' 'glazer' 'good' 'government' 'great' 'group' 'growth' 'half'\n",
      " 'high' 'home' 'howard' 'hunting' 'iaaf' 'including' 'information'\n",
      " 'injury' 'internet' 'ireland' 'jones' 'just' 'labour' 'like' 'liverpool'\n",
      " 'lord' 'mail' 'make' 'market' 'match' 'microsoft' 'million' 'minister'\n",
      " 'mobile' 'mps' 'mr' 'music' 'musical' 'net' 'new' 'nintendo' 'number'\n",
      " 'oil' 'old' 'olympic' 'online' 'party' 'people' 'plans' 'play' 'players'\n",
      " 'police' 'president' 'prices' 'public' 'rights' 'roddick' 'rugby' 'said'\n",
      " 'sales' 'says' 'season' 'secretary' 'series' 'service' 'services' 'set'\n",
      " 'shares' 'singer' 'site' 'software' 'sony' 'spam' 'star' 'stars' 'state'\n",
      " 'team' 'technology' 'time' 'trade' 'tv' 'uk' 'united' 'use' 'users'\n",
      " 'using' 'video' 'virus' 'web' 'win' 'won' 'world' 'year' 'year old']\n"
     ]
    }
   ],
   "source": [
    "print(\"Features selected by SelectFromModel: \", feature_names[model.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline with the tfidf representation and a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('classification', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fit the pipeline on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vectorizer', CountVectorizer()),\n",
       "  ('feature_extraction', TfidfTransformer()),\n",
       "  ('classification', RandomForestClassifier())],\n",
       " 'verbose': False,\n",
       " 'vectorizer': CountVectorizer(),\n",
       " 'feature_extraction': TfidfTransformer(),\n",
       " 'classification': RandomForestClassifier(),\n",
       " 'vectorizer__analyzer': 'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': 'strict',\n",
       " 'vectorizer__dtype': numpy.int64,\n",
       " 'vectorizer__encoding': 'utf-8',\n",
       " 'vectorizer__input': 'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': None,\n",
       " 'vectorizer__vocabulary': None,\n",
       " 'feature_extraction__norm': 'l2',\n",
       " 'feature_extraction__smooth_idf': True,\n",
       " 'feature_extraction__sublinear_tf': False,\n",
       " 'feature_extraction__use_idf': True,\n",
       " 'classification__bootstrap': True,\n",
       " 'classification__ccp_alpha': 0.0,\n",
       " 'classification__class_weight': None,\n",
       " 'classification__criterion': 'gini',\n",
       " 'classification__max_depth': None,\n",
       " 'classification__max_features': 'auto',\n",
       " 'classification__max_leaf_nodes': None,\n",
       " 'classification__max_samples': None,\n",
       " 'classification__min_impurity_decrease': 0.0,\n",
       " 'classification__min_impurity_split': None,\n",
       " 'classification__min_samples_leaf': 1,\n",
       " 'classification__min_samples_split': 2,\n",
       " 'classification__min_weight_fraction_leaf': 0.0,\n",
       " 'classification__n_estimators': 100,\n",
       " 'classification__n_jobs': None,\n",
       " 'classification__oob_score': False,\n",
       " 'classification__random_state': None,\n",
       " 'classification__verbose': 0,\n",
       " 'classification__warm_start': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train, y_train)\n",
    "clf1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Use the pipeline to predict the outcome variable on your test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.95      0.97      0.96        92\n",
      "entertainment       1.00      0.93      0.96        84\n",
      "     politics       0.92      0.95      0.94        77\n",
      "        sport       0.98      0.99      0.99       111\n",
      "         tech       0.99      1.00      0.99        81\n",
      "\n",
      "     accuracy                           0.97       445\n",
      "    macro avg       0.97      0.97      0.97       445\n",
      " weighted avg       0.97      0.97      0.97       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = clf1.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred1, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second pipeline with the tfidf representation and a random forest classifier with the addition \n",
    "of an embedded feature selection using the SVM classification method with L1 penalty. \n",
    "\n",
    "Fit the pipeline on your training set and test it with the test set. How does the performance change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "    ('classification', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vectorizer', CountVectorizer()),\n",
       "  ('feature_extraction', TfidfTransformer()),\n",
       "  ('feature_selection',\n",
       "   SelectFromModel(estimator=LinearSVC(dual=False, penalty='l1'))),\n",
       "  ('classification', RandomForestClassifier())],\n",
       " 'verbose': False,\n",
       " 'vectorizer': CountVectorizer(),\n",
       " 'feature_extraction': TfidfTransformer(),\n",
       " 'feature_selection': SelectFromModel(estimator=LinearSVC(dual=False, penalty='l1')),\n",
       " 'classification': RandomForestClassifier(),\n",
       " 'vectorizer__analyzer': 'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': 'strict',\n",
       " 'vectorizer__dtype': numpy.int64,\n",
       " 'vectorizer__encoding': 'utf-8',\n",
       " 'vectorizer__input': 'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': None,\n",
       " 'vectorizer__vocabulary': None,\n",
       " 'feature_extraction__norm': 'l2',\n",
       " 'feature_extraction__smooth_idf': True,\n",
       " 'feature_extraction__sublinear_tf': False,\n",
       " 'feature_extraction__use_idf': True,\n",
       " 'feature_selection__estimator__C': 1.0,\n",
       " 'feature_selection__estimator__class_weight': None,\n",
       " 'feature_selection__estimator__dual': False,\n",
       " 'feature_selection__estimator__fit_intercept': True,\n",
       " 'feature_selection__estimator__intercept_scaling': 1,\n",
       " 'feature_selection__estimator__loss': 'squared_hinge',\n",
       " 'feature_selection__estimator__max_iter': 1000,\n",
       " 'feature_selection__estimator__multi_class': 'ovr',\n",
       " 'feature_selection__estimator__penalty': 'l1',\n",
       " 'feature_selection__estimator__random_state': None,\n",
       " 'feature_selection__estimator__tol': 0.0001,\n",
       " 'feature_selection__estimator__verbose': 0,\n",
       " 'feature_selection__estimator': LinearSVC(dual=False, penalty='l1'),\n",
       " 'feature_selection__max_features': None,\n",
       " 'feature_selection__norm_order': 1,\n",
       " 'feature_selection__prefit': False,\n",
       " 'feature_selection__threshold': None,\n",
       " 'classification__bootstrap': True,\n",
       " 'classification__ccp_alpha': 0.0,\n",
       " 'classification__class_weight': None,\n",
       " 'classification__criterion': 'gini',\n",
       " 'classification__max_depth': None,\n",
       " 'classification__max_features': 'auto',\n",
       " 'classification__max_leaf_nodes': None,\n",
       " 'classification__max_samples': None,\n",
       " 'classification__min_impurity_decrease': 0.0,\n",
       " 'classification__min_impurity_split': None,\n",
       " 'classification__min_samples_leaf': 1,\n",
       " 'classification__min_samples_split': 2,\n",
       " 'classification__min_weight_fraction_leaf': 0.0,\n",
       " 'classification__n_estimators': 100,\n",
       " 'classification__n_jobs': None,\n",
       " 'classification__oob_score': False,\n",
       " 'classification__random_state': None,\n",
       " 'classification__verbose': 0,\n",
       " 'classification__warm_start': False}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train)\n",
    "clf2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.91      0.93      0.92        92\n",
      "entertainment       0.96      0.92      0.94        84\n",
      "     politics       0.91      0.91      0.91        77\n",
      "        sport       0.99      0.99      0.99       111\n",
      "         tech       0.94      0.96      0.95        81\n",
      "\n",
      "     accuracy                           0.95       445\n",
      "    macro avg       0.94      0.94      0.94       445\n",
      " weighted avg       0.95      0.95      0.95       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = clf2.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred2, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your third and forth pipelines with the tfidf representation, a chi2 feature selection (with 20 and 200 features for clf3 and clf4, respectively), and a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('feature_selection', SelectKBest(chi2, k=20)),\n",
    "    ('classification', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vectorizer', CountVectorizer()),\n",
       "  ('feature_extraction', TfidfTransformer()),\n",
       "  ('feature_selection',\n",
       "   SelectKBest(k=20, score_func=<function chi2 at 0x7fc5973b5d30>)),\n",
       "  ('classification', RandomForestClassifier())],\n",
       " 'verbose': False,\n",
       " 'vectorizer': CountVectorizer(),\n",
       " 'feature_extraction': TfidfTransformer(),\n",
       " 'feature_selection': SelectKBest(k=20, score_func=<function chi2 at 0x7fc5973b5d30>),\n",
       " 'classification': RandomForestClassifier(),\n",
       " 'vectorizer__analyzer': 'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': 'strict',\n",
       " 'vectorizer__dtype': numpy.int64,\n",
       " 'vectorizer__encoding': 'utf-8',\n",
       " 'vectorizer__input': 'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': None,\n",
       " 'vectorizer__vocabulary': None,\n",
       " 'feature_extraction__norm': 'l2',\n",
       " 'feature_extraction__smooth_idf': True,\n",
       " 'feature_extraction__sublinear_tf': False,\n",
       " 'feature_extraction__use_idf': True,\n",
       " 'feature_selection__k': 20,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection._univariate_selection.chi2(X, y)>,\n",
       " 'classification__bootstrap': True,\n",
       " 'classification__ccp_alpha': 0.0,\n",
       " 'classification__class_weight': None,\n",
       " 'classification__criterion': 'gini',\n",
       " 'classification__max_depth': None,\n",
       " 'classification__max_features': 'auto',\n",
       " 'classification__max_leaf_nodes': None,\n",
       " 'classification__max_samples': None,\n",
       " 'classification__min_impurity_decrease': 0.0,\n",
       " 'classification__min_impurity_split': None,\n",
       " 'classification__min_samples_leaf': 1,\n",
       " 'classification__min_samples_split': 2,\n",
       " 'classification__min_weight_fraction_leaf': 0.0,\n",
       " 'classification__n_estimators': 100,\n",
       " 'classification__n_jobs': None,\n",
       " 'classification__oob_score': False,\n",
       " 'classification__random_state': None,\n",
       " 'classification__verbose': 0,\n",
       " 'classification__warm_start': False}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X_train, y_train)\n",
    "clf3.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.65      0.46      0.54        92\n",
      "entertainment       0.81      0.57      0.67        84\n",
      "     politics       0.79      0.73      0.76        77\n",
      "        sport       0.63      0.99      0.77       111\n",
      "         tech       0.88      0.81      0.85        81\n",
      "\n",
      "     accuracy                           0.72       445\n",
      "    macro avg       0.75      0.71      0.72       445\n",
      " weighted avg       0.74      0.72      0.71       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = clf3.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred3, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('feature_selection', SelectKBest(chi2, k=200)),\n",
    "    ('classification', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vectorizer', CountVectorizer()),\n",
       "  ('feature_extraction', TfidfTransformer()),\n",
       "  ('feature_selection',\n",
       "   SelectKBest(k=200, score_func=<function chi2 at 0x7fc5973b5d30>)),\n",
       "  ('classification', RandomForestClassifier())],\n",
       " 'verbose': False,\n",
       " 'vectorizer': CountVectorizer(),\n",
       " 'feature_extraction': TfidfTransformer(),\n",
       " 'feature_selection': SelectKBest(k=200, score_func=<function chi2 at 0x7fc5973b5d30>),\n",
       " 'classification': RandomForestClassifier(),\n",
       " 'vectorizer__analyzer': 'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': 'strict',\n",
       " 'vectorizer__dtype': numpy.int64,\n",
       " 'vectorizer__encoding': 'utf-8',\n",
       " 'vectorizer__input': 'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': None,\n",
       " 'vectorizer__vocabulary': None,\n",
       " 'feature_extraction__norm': 'l2',\n",
       " 'feature_extraction__smooth_idf': True,\n",
       " 'feature_extraction__sublinear_tf': False,\n",
       " 'feature_extraction__use_idf': True,\n",
       " 'feature_selection__k': 200,\n",
       " 'feature_selection__score_func': <function sklearn.feature_selection._univariate_selection.chi2(X, y)>,\n",
       " 'classification__bootstrap': True,\n",
       " 'classification__ccp_alpha': 0.0,\n",
       " 'classification__class_weight': None,\n",
       " 'classification__criterion': 'gini',\n",
       " 'classification__max_depth': None,\n",
       " 'classification__max_features': 'auto',\n",
       " 'classification__max_leaf_nodes': None,\n",
       " 'classification__max_samples': None,\n",
       " 'classification__min_impurity_decrease': 0.0,\n",
       " 'classification__min_impurity_split': None,\n",
       " 'classification__min_samples_leaf': 1,\n",
       " 'classification__min_samples_split': 2,\n",
       " 'classification__min_weight_fraction_leaf': 0.0,\n",
       " 'classification__n_estimators': 100,\n",
       " 'classification__n_jobs': None,\n",
       " 'classification__oob_score': False,\n",
       " 'classification__random_state': None,\n",
       " 'classification__verbose': 0,\n",
       " 'classification__warm_start': False}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(X_train, y_train)\n",
    "clf4.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.86      0.92      0.89        92\n",
      "entertainment       0.97      0.89      0.93        84\n",
      "     politics       0.95      0.90      0.92        77\n",
      "        sport       0.97      0.99      0.98       111\n",
      "         tech       0.94      0.96      0.95        81\n",
      "\n",
      "     accuracy                           0.94       445\n",
      "    macro avg       0.94      0.93      0.94       445\n",
      " weighted avg       0.94      0.94      0.94       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred4 = clf4.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred4, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the learner by simply plugging a different classifier object into our pipeline. \n",
    "\n",
    "Create your fifth pipeline with L1 norm SVM for the feature selection method and naive Bayes for the classifier. \n",
    "Compare your results on the test set with the previous pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "    ('classification', MultinomialNB(alpha=0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vectorizer', CountVectorizer()),\n",
       "  ('feature_extraction', TfidfTransformer()),\n",
       "  ('feature_selection',\n",
       "   SelectFromModel(estimator=LinearSVC(dual=False, penalty='l1'))),\n",
       "  ('classification', MultinomialNB(alpha=0.01))],\n",
       " 'verbose': False,\n",
       " 'vectorizer': CountVectorizer(),\n",
       " 'feature_extraction': TfidfTransformer(),\n",
       " 'feature_selection': SelectFromModel(estimator=LinearSVC(dual=False, penalty='l1')),\n",
       " 'classification': MultinomialNB(alpha=0.01),\n",
       " 'vectorizer__analyzer': 'word',\n",
       " 'vectorizer__binary': False,\n",
       " 'vectorizer__decode_error': 'strict',\n",
       " 'vectorizer__dtype': numpy.int64,\n",
       " 'vectorizer__encoding': 'utf-8',\n",
       " 'vectorizer__input': 'content',\n",
       " 'vectorizer__lowercase': True,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__max_features': None,\n",
       " 'vectorizer__min_df': 1,\n",
       " 'vectorizer__ngram_range': (1, 1),\n",
       " 'vectorizer__preprocessor': None,\n",
       " 'vectorizer__stop_words': None,\n",
       " 'vectorizer__strip_accents': None,\n",
       " 'vectorizer__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vectorizer__tokenizer': None,\n",
       " 'vectorizer__vocabulary': None,\n",
       " 'feature_extraction__norm': 'l2',\n",
       " 'feature_extraction__smooth_idf': True,\n",
       " 'feature_extraction__sublinear_tf': False,\n",
       " 'feature_extraction__use_idf': True,\n",
       " 'feature_selection__estimator__C': 1.0,\n",
       " 'feature_selection__estimator__class_weight': None,\n",
       " 'feature_selection__estimator__dual': False,\n",
       " 'feature_selection__estimator__fit_intercept': True,\n",
       " 'feature_selection__estimator__intercept_scaling': 1,\n",
       " 'feature_selection__estimator__loss': 'squared_hinge',\n",
       " 'feature_selection__estimator__max_iter': 1000,\n",
       " 'feature_selection__estimator__multi_class': 'ovr',\n",
       " 'feature_selection__estimator__penalty': 'l1',\n",
       " 'feature_selection__estimator__random_state': None,\n",
       " 'feature_selection__estimator__tol': 0.0001,\n",
       " 'feature_selection__estimator__verbose': 0,\n",
       " 'feature_selection__estimator': LinearSVC(dual=False, penalty='l1'),\n",
       " 'feature_selection__max_features': None,\n",
       " 'feature_selection__norm_order': 1,\n",
       " 'feature_selection__prefit': False,\n",
       " 'feature_selection__threshold': None,\n",
       " 'classification__alpha': 0.01,\n",
       " 'classification__class_prior': None,\n",
       " 'classification__fit_prior': True}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.fit(X_train, y_train)\n",
    "clf5.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.96      0.93      0.95        92\n",
      "entertainment       1.00      0.94      0.97        84\n",
      "     politics       0.95      0.99      0.97        77\n",
      "        sport       1.00      1.00      1.00       111\n",
      "         tech       0.93      0.98      0.95        81\n",
      "\n",
      "     accuracy                           0.97       445\n",
      "    macro avg       0.97      0.97      0.97       445\n",
      " weighted avg       0.97      0.97      0.97       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred5 = clf5.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred5, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension reduction - PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction methods such as PCA and SVD can be used to project the data into a lower dimensional space.\n",
    "\n",
    "If you run PCA with your text data, you might end up with the message \"PCA does not support sparse input. See TruncatedSVD for a possible alternative.\" \n",
    "\n",
    "Therefore, we will use the Truncated SVD function from the sklearn package and we want to find out how much of the variance in the BBC data set is explained with different components. For this, first create a tfidf matrix and use that to make a co-occurrence matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the TFIDF vectorizer: (1780, 26739)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "X = tfidf_vect.fit_transform(X_train)\n",
    "\n",
    "Xc = (X.T * X) # this is co-occurrence matrix in sparse csr format\n",
    "Xc.setdiag(0) # sometimes you want to fill same word cooccurence to 0\n",
    "print(\"Shape of the TFIDF vectorizer:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.00024418 0.         ... 0.         0.         0.        ]\n",
      " [0.00024418 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Xc.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'moya': 16209,\n",
       " 'emotional': 8651,\n",
       " 'at': 2701,\n",
       " 'davis': 6926,\n",
       " 'cup': 6713,\n",
       " 'win': 26258,\n",
       " 'carlos': 4732,\n",
       " 'described': 7350,\n",
       " 'spain': 22477,\n",
       " 'victory': 25605,\n",
       " 'as': 2586,\n",
       " 'the': 24062,\n",
       " 'highlight': 11819,\n",
       " 'of': 17001,\n",
       " 'his': 11872,\n",
       " 'career': 4712,\n",
       " 'after': 1753,\n",
       " 'he': 11591,\n",
       " 'beat': 3292,\n",
       " 'andy': 2196,\n",
       " 'roddick': 20643,\n",
       " 'to': 24311,\n",
       " 'end': 8715,\n",
       " 'usa': 25352,\n",
       " 'challenge': 5012,\n",
       " 'in': 12538,\n",
       " 'seville': 21583,\n",
       " 'made': 14933,\n",
       " 'up': 25285,\n",
       " 'for': 10089,\n",
       " 'missing': 15914,\n",
       " '2000': 428,\n",
       " 'through': 24179,\n",
       " 'injury': 12794,\n",
       " 'by': 4484,\n",
       " 'beating': 3295,\n",
       " 'give': 10798,\n",
       " 'hosts': 12081,\n",
       " 'an': 2147,\n",
       " 'unassailable': 24929,\n",
       " 'lead': 14223,\n",
       " 'have': 11560,\n",
       " 'woken': 26365,\n",
       " 'so': 22302,\n",
       " 'many': 15140,\n",
       " 'nights': 16676,\n",
       " 'dreaming': 8137,\n",
       " 'this': 24124,\n",
       " 'day': 6934,\n",
       " 'said': 20934,\n",
       " 'all': 1955,\n",
       " 'my': 16350,\n",
       " 'energy': 8752,\n",
       " 'has': 11525,\n",
       " 'been': 3342,\n",
       " 'focused': 10027,\n",
       " 'on': 17097,\n",
       " 'today': 24317,\n",
       " 'what': 26113,\n",
       " 'lived': 14610,\n",
       " 'do': 7916,\n",
       " 'not': 16800,\n",
       " 'think': 24111,\n",
       " 'will': 26230,\n",
       " 'live': 14608,\n",
       " 'again': 1760,\n",
       " 'only': 17111,\n",
       " 'other': 17277,\n",
       " 'title': 24300,\n",
       " 'came': 4575,\n",
       " 'two': 24844,\n",
       " 'years': 26599,\n",
       " 'ago': 1797,\n",
       " 'valencia': 25425,\n",
       " 'when': 26127,\n",
       " 'they': 24099,\n",
       " 'australia': 2816,\n",
       " 'and': 2180,\n",
       " 'nicknamed': 16649,\n",
       " 'charly': 5091,\n",
       " 'admitted': 1643,\n",
       " 'is': 13176,\n",
       " 'dream': 8135,\n",
       " 'was': 25919,\n",
       " 'bit': 3648,\n",
       " 'nervous': 16561,\n",
       " 'outset': 17350,\n",
       " 'some': 22373,\n",
       " 'people': 17913,\n",
       " 'that': 24054,\n",
       " 'am': 2046,\n",
       " 'obsessed': 16950,\n",
       " 'but': 4452,\n",
       " 'it': 13220,\n",
       " 'better': 3533,\n",
       " 'way': 25965,\n",
       " 'helps': 11711,\n",
       " 'me': 15467,\n",
       " 'reach': 19543,\n",
       " 'goals': 10896,\n",
       " 'if': 12350,\n",
       " 'really': 19578,\n",
       " 'incredible': 12608,\n",
       " 'get': 10709,\n",
       " 'winning': 26291,\n",
       " 'point': 18391,\n",
       " 'something': 22380,\n",
       " 'spanish': 22488,\n",
       " 'captain': 4680,\n",
       " 'jordi': 13487,\n",
       " 'arrese': 2538,\n",
       " 'played': 18300,\n",
       " 'great': 11085,\n",
       " 'game': 10498,\n",
       " 'opportunity': 17167,\n",
       " 'hasn': 11529,\n",
       " 'let': 14373,\n",
       " 'us': 25351,\n",
       " 'down': 8069,\n",
       " 'had': 11313,\n",
       " 'lost': 14750,\n",
       " 'three': 24158,\n",
       " 'times': 24259,\n",
       " 'him': 11839,\n",
       " 'waiting': 25820,\n",
       " 'be': 3266,\n",
       " 'position': 18525,\n",
       " 'also': 2021,\n",
       " 'remarkable': 20007,\n",
       " 'performance': 17946,\n",
       " 'rafael': 19368,\n",
       " 'nadal': 16373,\n",
       " 'who': 26173,\n",
       " 'opening': 17137,\n",
       " 'singles': 22020,\n",
       " 'aged': 1765,\n",
       " '18': 273,\n",
       " '185': 290,\n",
       " 'days': 6938,\n",
       " 'mallorcan': 15052,\n",
       " 'became': 3314,\n",
       " 'youngest': 26642,\n",
       " 'player': 18301,\n",
       " 'finish': 9808,\n",
       " 'year': 26595,\n",
       " 'afterwards': 1757,\n",
       " 'coach': 5541,\n",
       " 'patrick': 17763,\n",
       " 'mcenroe': 15416,\n",
       " 'wants': 25871,\n",
       " 'rest': 20254,\n",
       " 'team': 23835,\n",
       " 'play': 18294,\n",
       " 'more': 16105,\n",
       " 'tennis': 23954,\n",
       " 'clay': 5410,\n",
       " 'hone': 11992,\n",
       " 'their': 24071,\n",
       " 'skills': 22086,\n",
       " 'surface': 23428,\n",
       " 'help': 11705,\n",
       " 'these': 24098,\n",
       " 'guys': 11285,\n",
       " 'even': 9083,\n",
       " 'slow': 22183,\n",
       " 'hard': 11459,\n",
       " 'courts': 6453,\n",
       " 'learn': 14258,\n",
       " 'how': 12124,\n",
       " 'mix': 15944,\n",
       " 'things': 24110,\n",
       " 'little': 14603,\n",
       " 'smarter': 22214,\n",
       " 'tactically': 23661,\n",
       " 'obviously': 16963,\n",
       " 'unrealistic': 25202,\n",
       " 'say': 21091,\n",
       " 'we': 25974,\n",
       " 're': 19541,\n",
       " 'going': 10915,\n",
       " 'just': 13586,\n",
       " 'start': 22840,\n",
       " 'playing': 18304,\n",
       " 'constantly': 6090,\n",
       " 'with': 26325,\n",
       " 'schedule': 21155,\n",
       " 'certainly': 4972,\n",
       " 'can': 4602,\n",
       " 'put': 19204,\n",
       " 'work': 26420,\n",
       " 'appropriate': 2415,\n",
       " 'time': 24253,\n",
       " 'couple': 6433,\n",
       " 'events': 9088,\n",
       " 'against': 1761,\n",
       " 'are': 2471,\n",
       " 'best': 3513,\n",
       " 'stuff': 23180,\n",
       " 'left': 14290,\n",
       " 'frustrated': 10358,\n",
       " 'losing': 14746,\n",
       " 'both': 3970,\n",
       " 'olympic': 17085,\n",
       " 'stadium': 22755,\n",
       " 'tough': 24434,\n",
       " 'because': 3315,\n",
       " 'felt': 9634,\n",
       " 'like': 14494,\n",
       " 'whole': 26176,\n",
       " 'one': 17101,\n",
       " 'top': 24372,\n",
       " 'courters': 6446,\n",
       " 'world': 26443,\n",
       " 'american': 2093,\n",
       " 'chances': 5034,\n",
       " 'didn': 7525,\n",
       " 'convert': 6237,\n",
       " 'them': 24074,\n",
       " 'bottom': 3980,\n",
       " 'line': 14538,\n",
       " 'were': 26082,\n",
       " 'than': 24045,\n",
       " 'weekend': 26030,\n",
       " 'out': 17291,\n",
       " 'took': 24362,\n",
       " 'care': 4710,\n",
       " 'business': 4443,\n",
       " 'simple': 21979,\n",
       " 'bryan': 4294,\n",
       " 'twins': 24837,\n",
       " 'keep': 13697,\n",
       " 'hopes': 12031,\n",
       " 'alive': 1954,\n",
       " 'united': 25136,\n",
       " 'states': 22857,\n",
       " 'kept': 13737,\n",
       " 'final': 9767,\n",
       " 'saturday': 21060,\n",
       " 'doubles': 8052,\n",
       " 'rubber': 20789,\n",
       " 'leaving': 14271,\n",
       " 'ahead': 1816,\n",
       " 'into': 13020,\n",
       " 'masters': 15295,\n",
       " 'champions': 5026,\n",
       " 'mike': 15763,\n",
       " 'bob': 3819,\n",
       " 'thrashed': 24148,\n",
       " 'juan': 13520,\n",
       " 'ferrero': 9661,\n",
       " 'tommy': 24345,\n",
       " 'robredo': 20617,\n",
       " 'front': 10335,\n",
       " 'partisan': 17694,\n",
       " 'crowd': 6627,\n",
       " 'would': 26467,\n",
       " 'given': 10801,\n",
       " 'outclassed': 17297,\n",
       " 'sunday': 23345,\n",
       " 'reverse': 20377,\n",
       " 'takes': 23690,\n",
       " 'before': 3349,\n",
       " 'faces': 9388,\n",
       " 'mardy': 15169,\n",
       " 'fish': 9863,\n",
       " 'feels': 9613,\n",
       " 'good': 10942,\n",
       " 'don': 7990,\n",
       " 'tomorrow': 24346,\n",
       " 'those': 24139,\n",
       " 'another': 2284,\n",
       " 'shot': 21827,\n",
       " 'go': 10889,\n",
       " 'sleep': 22141,\n",
       " 'added': 1586,\n",
       " 'confident': 5959,\n",
       " 'first': 9854,\n",
       " 'match': 15301,\n",
       " 'then': 24079,\n",
       " 'anything': 2330,\n",
       " 'happen': 11443,\n",
       " 'chose': 5247,\n",
       " 'old': 17063,\n",
       " 'epic': 8890,\n",
       " 'over': 17372,\n",
       " 'friday': 10310,\n",
       " 'replaced': 20115,\n",
       " 'former': 10147,\n",
       " 'number': 16872,\n",
       " 'pair': 17541,\n",
       " 'depth': 7320,\n",
       " 'teams': 23838,\n",
       " '26': 544,\n",
       " 'won': 26382,\n",
       " 'four': 10196,\n",
       " 'matches': 15304,\n",
       " 'quickly': 19286,\n",
       " 'silenced': 21952,\n",
       " 'huge': 12154,\n",
       " 'racing': 19335,\n",
       " 'set': 21552,\n",
       " 'love': 14767,\n",
       " 'spaniards': 22487,\n",
       " 'twice': 24831,\n",
       " 'surrendered': 23457,\n",
       " 'breaks': 4110,\n",
       " 'serve': 21540,\n",
       " 'second': 21363,\n",
       " 'bryans': 4295,\n",
       " 'broke': 4230,\n",
       " 'served': 21541,\n",
       " 'dropped': 8178,\n",
       " 'third': 24117,\n",
       " 'unflappable': 25085,\n",
       " 'brothers': 4256,\n",
       " 'powered': 18590,\n",
       " 'impressive': 12516,\n",
       " 'upset': 25322,\n",
       " 'hinted': 11857,\n",
       " 'further': 10431,\n",
       " 'dissatisfaction': 7813,\n",
       " 'defeat': 7086,\n",
       " 'difficult': 7548,\n",
       " 'players': 18302,\n",
       " 'everything': 9103,\n",
       " 'calculated': 4534,\n",
       " 'very': 25557,\n",
       " 'surprised': 23450,\n",
       " 'named': 16392,\n",
       " 'hardly': 11472,\n",
       " 'badly': 2989,\n",
       " 'right': 20505,\n",
       " 'christmas': 5259,\n",
       " 'sales': 20955,\n",
       " 'worst': 26460,\n",
       " 'since': 22004,\n",
       " '1981': 395,\n",
       " 'uk': 24885,\n",
       " 'retail': 20299,\n",
       " 'fell': 9626,\n",
       " 'december': 7011,\n",
       " 'failing': 9417,\n",
       " 'meet': 15522,\n",
       " 'expectations': 9245,\n",
       " 'making': 15020,\n",
       " 'counts': 6429,\n",
       " 'month': 16078,\n",
       " 'rise': 20551,\n",
       " 'november': 16846,\n",
       " 'office': 17021,\n",
       " 'national': 16450,\n",
       " 'statistics': 22866,\n",
       " 'ons': 17113,\n",
       " 'revised': 20391,\n",
       " 'annual': 2270,\n",
       " '2004': 434,\n",
       " 'rate': 19496,\n",
       " 'growth': 11187,\n",
       " 'from': 10333,\n",
       " 'estimated': 9008,\n",
       " 'retailers': 20301,\n",
       " 'already': 2019,\n",
       " 'reported': 20129,\n",
       " 'poor': 18464,\n",
       " 'figures': 9739,\n",
       " 'clothing': 5508,\n",
       " 'non': 16751,\n",
       " 'specialist': 22528,\n",
       " 'stores': 23031,\n",
       " 'hit': 11883,\n",
       " 'internet': 12982,\n",
       " 'showing': 21851,\n",
       " 'any': 2325,\n",
       " 'significant': 21943,\n",
       " 'according': 1473,\n",
       " 'last': 14144,\n",
       " 'endured': 8741,\n",
       " 'tougher': 24436,\n",
       " '23': 502,\n",
       " 'previously': 18780,\n",
       " 'plunged': 18359,\n",
       " 'echoed': 8379,\n",
       " 'earlier': 8318,\n",
       " 'caution': 4873,\n",
       " 'bank': 3095,\n",
       " 'england': 8778,\n",
       " 'governor': 10998,\n",
       " 'mervyn': 15649,\n",
       " 'king': 13820,\n",
       " 'read': 19553,\n",
       " 'too': 24361,\n",
       " 'much': 16240,\n",
       " 'analysts': 2160,\n",
       " 'positive': 18530,\n",
       " 'gloss': 10864,\n",
       " 'pointing': 18395,\n",
       " 'seasonally': 21345,\n",
       " 'adjusted': 1620,\n",
       " 'showed': 21847,\n",
       " 'comparable': 5784,\n",
       " '2003': 433,\n",
       " 'jump': 13560,\n",
       " 'roughly': 20738,\n",
       " 'recent': 19643,\n",
       " 'averages': 2874,\n",
       " 'although': 2032,\n",
       " 'below': 3423,\n",
       " 'serious': 21530,\n",
       " 'booms': 3916,\n",
       " 'seen': 21408,\n",
       " '1990s': 406,\n",
       " 'volume': 25755,\n",
       " 'outperformed': 17338,\n",
       " 'measures': 15486,\n",
       " 'actual': 1562,\n",
       " 'spending': 22577,\n",
       " 'indication': 12640,\n",
       " 'consumers': 6120,\n",
       " 'looking': 14718,\n",
       " 'bargains': 3139,\n",
       " 'cutting': 6771,\n",
       " 'prices': 18784,\n",
       " 'however': 12131,\n",
       " 'reports': 20134,\n",
       " 'high': 11807,\n",
       " 'street': 23094,\n",
       " 'weakness': 25981,\n",
       " 'sector': 21380,\n",
       " 'morrisons': 16126,\n",
       " 'woolworths': 26412,\n",
       " 'house': 12107,\n",
       " 'fraser': 10249,\n",
       " 'marks': 15209,\n",
       " 'spencer': 22575,\n",
       " 'big': 3578,\n",
       " 'food': 10067,\n",
       " 'festive': 9676,\n",
       " 'period': 17957,\n",
       " 'disappointing': 7647,\n",
       " 'british': 4195,\n",
       " 'consortium': 6081,\n",
       " 'survey': 23468,\n",
       " 'found': 10188,\n",
       " '10': 55,\n",
       " 'yet': 26614,\n",
       " 'including': 12582,\n",
       " 'hmv': 11903,\n",
       " 'monsoon': 16067,\n",
       " 'jessops': 13387,\n",
       " 'body': 3832,\n",
       " 'shop': 21803,\n",
       " 'tesco': 23995,\n",
       " 'well': 26064,\n",
       " 'investec': 13068,\n",
       " 'chief': 5182,\n",
       " 'economist': 8393,\n",
       " 'philip': 18088,\n",
       " 'shaw': 21688,\n",
       " 'did': 7521,\n",
       " 'expect': 9242,\n",
       " 'immediate': 12433,\n",
       " 'effect': 8447,\n",
       " 'interest': 12958,\n",
       " 'rates': 19498,\n",
       " 'weak': 25975,\n",
       " 'indicated': 12637,\n",
       " 'night': 16671,\n",
       " 'you': 26638,\n",
       " 'accurate': 1498,\n",
       " 'impression': 12513,\n",
       " 'trading': 24502,\n",
       " 'until': 25255,\n",
       " 'about': 1381,\n",
       " 'easter': 8349,\n",
       " 'mr': 16225,\n",
       " 'our': 17285,\n",
       " 'view': 25618,\n",
       " 'its': 13233,\n",
       " 'powder': 18585,\n",
       " 'dry': 8200,\n",
       " 'wait': 25816,\n",
       " 'see': 21393,\n",
       " 'picture': 18146,\n",
       " 'jones': 13479,\n",
       " 'medals': 15499,\n",
       " 'must': 16332,\n",
       " 'guilty': 11239,\n",
       " 'anti': 2302,\n",
       " 'doping': 8028,\n",
       " 'agency': 1771,\n",
       " 'wada': 25800,\n",
       " 'dick': 7509,\n",
       " 'pound': 18576,\n",
       " 'says': 21095,\n",
       " 'marion': 15191,\n",
       " 'should': 21829,\n",
       " 'stripped': 23135,\n",
       " 'her': 11735,\n",
       " 'taking': 23691,\n",
       " 'banned': 3108,\n",
       " 'substances': 23243,\n",
       " 'victor': 25599,\n",
       " 'conte': 6136,\n",
       " 'balco': 3030,\n",
       " 'laboratories': 14012,\n",
       " 'claims': 5350,\n",
       " 'sprinter': 22686,\n",
       " 'regularly': 19872,\n",
       " 'used': 25362,\n",
       " 'drugs': 8189,\n",
       " 'enhance': 8782,\n",
       " 'she': 21692,\n",
       " 'asked': 2618,\n",
       " 'there': 24089,\n",
       " 'timescale': 24260,\n",
       " 'could': 6399,\n",
       " 'taken': 23686,\n",
       " 'issue': 13212,\n",
       " 'under': 24987,\n",
       " 'international': 12977,\n",
       " 'committee': 5754,\n",
       " 'ioc': 13106,\n",
       " 'rules': 20826,\n",
       " 'athletes': 2706,\n",
       " 'caught': 4865,\n",
       " 'within': 26336,\n",
       " 'event': 9087,\n",
       " 'five': 9879,\n",
       " 'olympics': 17086,\n",
       " 'denies': 7251,\n",
       " 'using': 25373,\n",
       " 'take': 23684,\n",
       " 'legal': 14295,\n",
       " 'action': 1546,\n",
       " 'allegations': 1965,\n",
       " 'firm': 9849,\n",
       " 'centre': 4952,\n",
       " 'wide': 26189,\n",
       " 'reaching': 19546,\n",
       " 'investigation': 13074,\n",
       " 'continued': 6171,\n",
       " 'indeed': 12619,\n",
       " 'disappointment': 7649,\n",
       " 'lot': 14752,\n",
       " 'eminem': 8639,\n",
       " 'secret': 21369,\n",
       " 'gig': 10750,\n",
       " 'venue': 25525,\n",
       " 'revealed': 20359,\n",
       " 'rapper': 19473,\n",
       " 'intimate': 13013,\n",
       " 'london': 14696,\n",
       " 'following': 10054,\n",
       " 'show': 21839,\n",
       " 'river': 20570,\n",
       " 'thames': 24044,\n",
       " 'star': 22822,\n",
       " 'songs': 22388,\n",
       " 'showcasing': 21845,\n",
       " 'label': 14007,\n",
       " 'shady': 21618,\n",
       " 'records': 19697,\n",
       " 'islington': 13197,\n",
       " 'academy': 1422,\n",
       " 'performed': 17948,\n",
       " 'hms': 11902,\n",
       " 'belfast': 3385,\n",
       " 'which': 26135,\n",
       " 'docked': 7922,\n",
       " 'where': 26129,\n",
       " 'filmed': 9753,\n",
       " 'bbc': 3259,\n",
       " 'pops': 18473,\n",
       " 'arrived': 2547,\n",
       " 'appearance': 2366,\n",
       " 'mtv': 16237,\n",
       " 'europe': 9046,\n",
       " 'music': 16318,\n",
       " 'awards': 2900,\n",
       " 'rome': 20675,\n",
       " 'rap': 19467,\n",
       " 'acts': 1561,\n",
       " 'may': 15365,\n",
       " 'appear': 2365,\n",
       " 'include': 12579,\n",
       " 'stat': 22850,\n",
       " 'quo': 19309,\n",
       " 'proof': 18980,\n",
       " 'dj': 7905,\n",
       " 'green': 11097,\n",
       " 'lantern': 14115,\n",
       " 'swift': 23568,\n",
       " 'obie': 16918,\n",
       " 'trice': 24646,\n",
       " 'latest': 14152,\n",
       " 'album': 1901,\n",
       " 'soared': 22307,\n",
       " 'chart': 5095,\n",
       " 'sale': 20954,\n",
       " 'record': 19690,\n",
       " 'shops': 21808,\n",
       " 'encore': 8701,\n",
       " 'now': 16851,\n",
       " 'topper': 24377,\n",
       " 'sides': 21910,\n",
       " 'atlantic': 2717,\n",
       " 'debut': 6993,\n",
       " 'fourth': 10200,\n",
       " 'outsold': 17356,\n",
       " 'rivals': 20569,\n",
       " 'released': 19958,\n",
       " 'early': 8321,\n",
       " 'effort': 8457,\n",
       " 'combat': 5681,\n",
       " 'physical': 18119,\n",
       " 'online': 17110,\n",
       " 'piracy': 18210,\n",
       " 'includes': 12581,\n",
       " 'track': 24483,\n",
       " 'mosh': 16135,\n",
       " 'tirade': 24286,\n",
       " 'president': 18734,\n",
       " 'bush': 4439,\n",
       " 'presence': 18716,\n",
       " 'troops': 24701,\n",
       " 'iraq': 13130,\n",
       " 'criticised': 6591,\n",
       " 'april': 2426,\n",
       " 'led': 14282,\n",
       " '12': 119,\n",
       " 'viewers': 25621,\n",
       " 'complain': 5825,\n",
       " 'lewd': 14395,\n",
       " 'offensive': 17014,\n",
       " 'complaints': 5830,\n",
       " 'grabbing': 11009,\n",
       " 'crotch': 6623,\n",
       " 'upheld': 25301,\n",
       " 'performer': 17949,\n",
       " 'tone': 24348,\n",
       " 'act': 1543,\n",
       " 'rehearsal': 19885,\n",
       " 'ignored': 12368,\n",
       " 'request': 20160,\n",
       " 'during': 8269,\n",
       " 'broadcast': 4212,\n",
       " 'statement': 22854,\n",
       " 'gestures': 10708,\n",
       " 'part': 17678,\n",
       " 'culture': 6699,\n",
       " 'gone': 10933,\n",
       " 'beyond': 3550,\n",
       " 'expected': 9246,\n",
       " 'loses': 14745,\n",
       " 'customer': 6757,\n",
       " 'details': 7414,\n",
       " 'america': 2092,\n",
       " 'computer': 5878,\n",
       " 'tapes': 23751,\n",
       " 'containing': 6134,\n",
       " 'account': 1476,\n",
       " 'million': 15790,\n",
       " 'customers': 6758,\n",
       " 'federal': 9596,\n",
       " 'employees': 8670,\n",
       " 'several': 21577,\n",
       " 'members': 15569,\n",
       " 'senate': 21457,\n",
       " 'among': 2118,\n",
       " 'affected': 1725,\n",
       " 'vulnerable': 25791,\n",
       " 'identity': 12324,\n",
       " 'theft': 24070,\n",
       " 'sources': 22442,\n",
       " 'stolen': 23009,\n",
       " 'plane': 18261,\n",
       " 'baggage': 2999,\n",
       " 'handlers': 11410,\n",
       " 'gave': 10581,\n",
       " 'no': 16718,\n",
       " 'disappeared': 7643,\n",
       " 'probably': 18851,\n",
       " 'misused': 15933,\n",
       " 'accounts': 1484,\n",
       " 'being': 3375,\n",
       " 'monitoring': 16055,\n",
       " 'holders': 11942,\n",
       " 'notified': 16821,\n",
       " 'unusual': 25263,\n",
       " 'activity': 1556,\n",
       " 'detected': 7421,\n",
       " 'officials': 17027,\n",
       " 'went': 26079,\n",
       " 'while': 26138,\n",
       " 'shipped': 21765,\n",
       " 'back': 2945,\n",
       " 'data': 6905,\n",
       " 'law': 14191,\n",
       " 'authorities': 2837,\n",
       " 'done': 7999,\n",
       " 'robust': 20620,\n",
       " 'thorough': 24134,\n",
       " 'neither': 16547,\n",
       " 'nor': 16761,\n",
       " 'make': 15012,\n",
       " 'lightly': 14489,\n",
       " 'believe': 3395,\n",
       " 'alexandra': 1923,\n",
       " 'tower': 24460,\n",
       " 'spokeswoman': 22635,\n",
       " 'north': 16780,\n",
       " 'carolina': 4747,\n",
       " 'based': 3194,\n",
       " 'told': 24329,\n",
       " 'magazine': 14950,\n",
       " 'evidence': 9110,\n",
       " 'criminal': 6569,\n",
       " 'service': 21545,\n",
       " 'whose': 26185,\n",
       " 'brief': 4159,\n",
       " 'investigations': 13075,\n",
       " 'financial': 9779,\n",
       " 'crime': 6567,\n",
       " 'loss': 14747,\n",
       " 'new': 16598,\n",
       " 'york': 26633,\n",
       " 'senator': 21458,\n",
       " 'charles': 5086,\n",
       " 'schumer': 21200,\n",
       " 'commercial': 5735,\n",
       " 'whether': 26134,\n",
       " 'terrorism': 23990,\n",
       " 'or': 17193,\n",
       " 'complicated': 5845,\n",
       " 'background': 2960,\n",
       " 'checks': 5132,\n",
       " 'hired': 11866,\n",
       " 'increasingly': 12607,\n",
       " 'sensitive': 21480,\n",
       " 'positions': 18529,\n",
       " 'democrat': 7218,\n",
       " 'vermont': 25544,\n",
       " 'colleague': 5632,\n",
       " 'pat': 17737,\n",
       " 'leahy': 14237,\n",
       " 'credit': 6540,\n",
       " 'card': 4701,\n",
       " 'tracy': 24493,\n",
       " 'schmaler': 21171,\n",
       " '900': 1245,\n",
       " '000': 1,\n",
       " 'military': 15781,\n",
       " 'civilian': 5336,\n",
       " 'staff': 22757,\n",
       " 'defence': 7096,\n",
       " 'department': 7273,\n",
       " 'pentagon': 17910,\n",
       " 'spokesman': 22632,\n",
       " 'bollywood': 3860,\n",
       " 'dvd': 8281,\n",
       " 'fraudster': 10256,\n",
       " 'jailed': 13279,\n",
       " 'major': 15005,\n",
       " 'distributor': 7854,\n",
       " 'pirated': 18212,\n",
       " 'dvds': 8282,\n",
       " 'films': 9760,\n",
       " 'sent': 21485,\n",
       " 'prison': 18826,\n",
       " 'jayanti': 13336,\n",
       " 'amarishi': 2054,\n",
       " 'buhecha': 4339,\n",
       " 'cambridge': 4572,\n",
       " 'trademark': 24496,\n",
       " 'offences': 17008,\n",
       " 'sentenced': 21488,\n",
       " 'harrow': 11510,\n",
       " 'crown': 6632,\n",
       " 'court': 6442,\n",
       " 'tuesday': 24763,\n",
       " 'per': 17925,\n",
       " 'illegal': 12381,\n",
       " 'trade': 24494,\n",
       " 'called': 4552,\n",
       " 'biggest': 3580,\n",
       " 'pirates': 18213,\n",
       " 'sentencing': 21491,\n",
       " 'judge': 13528,\n",
       " 'phonographic': 18106,\n",
       " 'industry': 12685,\n",
       " 'bpi': 4037,\n",
       " 'worked': 26422,\n",
       " 'case': 4796,\n",
       " 'operation': 17149,\n",
       " 'launched': 14171,\n",
       " '2002': 432,\n",
       " 'received': 19638,\n",
       " 'activities': 1555,\n",
       " 'lasted': 14145,\n",
       " 'seven': 21571,\n",
       " 'heavy': 11652,\n",
       " 'penalty': 17887,\n",
       " 'enormous': 8805,\n",
       " 'damage': 6834,\n",
       " 'caused': 4868,\n",
       " 'legitimate': 14310,\n",
       " 'fake': 9439,\n",
       " 'manufactured': 15134,\n",
       " 'pakistan': 17549,\n",
       " 'malaysia': 15027,\n",
       " 'sold': 22347,\n",
       " 'wholesale': 26179,\n",
       " 'traded': 24495,\n",
       " 'conterfeit': 6154,\n",
       " 'stopped': 23023,\n",
       " 'car': 4693,\n",
       " 'standards': 22802,\n",
       " 'officers': 17023,\n",
       " 'uncovered': 24976,\n",
       " 'faked': 9440,\n",
       " 'inlay': 12804,\n",
       " 'cards': 4708,\n",
       " 'printed': 18814,\n",
       " 'registered': 19856,\n",
       " 'trademarks': 24497,\n",
       " 'despite': 7392,\n",
       " 'arrested': 2540,\n",
       " 'bailed': 3012,\n",
       " 'home': 11973,\n",
       " 'lock': 14665,\n",
       " 'contain': 6131,\n",
       " 'counterfeit': 6414,\n",
       " 'suspended': 23489,\n",
       " 'sued': 23289,\n",
       " 'employers': 8672,\n",
       " 'dealing': 6964,\n",
       " 'copies': 6284,\n",
       " 'classic': 5390,\n",
       " 'mohabbatein': 16009,\n",
       " 'film': 9752,\n",
       " 'distributors': 7855,\n",
       " 'hailed': 11322,\n",
       " 'conviction': 6247,\n",
       " 'boost': 3921,\n",
       " 'suffers': 23297,\n",
       " '40': 771,\n",
       " 'suffered': 23294,\n",
       " 'mainstream': 14997,\n",
       " 'productions': 18892,\n",
       " 'welcomed': 26060,\n",
       " 'news': 16613,\n",
       " 'sentence': 21487,\n",
       " 'warned': 25899,\n",
       " 'plenty': 18332,\n",
       " 'active': 1551,\n",
       " 'counterfeiters': 6415,\n",
       " 'organisation': 17220,\n",
       " 'director': 7616,\n",
       " 'david': 6923,\n",
       " 'martin': 15244,\n",
       " 'problem': 18858,\n",
       " 'simply': 21988,\n",
       " 'disappear': 7641,\n",
       " 'others': 17278,\n",
       " 'place': 18245,\n",
       " 'vital': 25710,\n",
       " 'efforts': 8459,\n",
       " 'field': 9712,\n",
       " 'german': 10696,\n",
       " 'goes': 10912,\n",
       " 'germany': 10699,\n",
       " 'economy': 8395,\n",
       " 'shrank': 21858,\n",
       " 'months': 16080,\n",
       " 'upsetting': 25324,\n",
       " 'sustained': 23503,\n",
       " 'recovery': 19707,\n",
       " 'confounded': 5978,\n",
       " 'expansion': 9237,\n",
       " 'quarter': 19252,\n",
       " 'contraction': 6184,\n",
       " 'estimate': 9007,\n",
       " 'zero': 26706,\n",
       " 'putting': 19208,\n",
       " 'standstill': 22810,\n",
       " 'july': 13557,\n",
       " 'onward': 17123,\n",
       " 'reliant': 19970,\n",
       " 'exports': 9311,\n",
       " 'unemployment': 25065,\n",
       " 'impending': 12465,\n",
       " 'cuts': 6768,\n",
       " 'welfare': 26063,\n",
       " 'mean': 15472,\n",
       " 'money': 16044,\n",
       " 'themselves': 24078,\n",
       " 'companies': 5780,\n",
       " 'volkswagen': 25752,\n",
       " 'daimlerchrysler': 6818,\n",
       " 'siemens': 21922,\n",
       " 'spent': 22579,\n",
       " 'talks': 23707,\n",
       " 'unions': 25129,\n",
       " 'trimming': 24669,\n",
       " 'jobs': 13431,\n",
       " 'costs': 6383,\n",
       " 'destatis': 7397,\n",
       " 'rising': 20555,\n",
       " 'outweighed': 17369,\n",
       " 'continuing': 6173,\n",
       " 'domestic': 7973,\n",
       " 'demand': 7202,\n",
       " 'relentless': 19964,\n",
       " 'value': 25441,\n",
       " 'euro': 9040,\n",
       " 'competitiveness': 5814,\n",
       " 'products': 18895,\n",
       " 'overseas': 17424,\n",
       " 'depress': 7312,\n",
       " 'prospects': 19018,\n",
       " 'nation': 16449,\n",
       " 'eurozone': 9056,\n",
       " 'senior': 21469,\n",
       " 'setting': 21560,\n",
       " 'european': 9047,\n",
       " 'central': 4946,\n",
       " 'beginning': 3356,\n",
       " 'talk': 23702,\n",
       " 'threat': 24151,\n",
       " 'inflation': 12729,\n",
       " 'prompting': 18972,\n",
       " 'fears': 9582,\n",
       " 'ecb': 8373,\n",
       " 'mandate': 15082,\n",
       " 'fight': 9729,\n",
       " 'boosting': 3923,\n",
       " 'threaten': 24152,\n",
       " 'tautou': 23806,\n",
       " 'da': 6800,\n",
       " 'vinci': 25655,\n",
       " 'french': 10293,\n",
       " 'actress': 1559,\n",
       " 'audrey': 2802,\n",
       " 'amelie': 2083,\n",
       " 'female': 9635,\n",
       " 'adaptation': 1574,\n",
       " 'code': 5577,\n",
       " 'movie': 16203,\n",
       " 'version': 25551,\n",
       " 'dan': 6852,\n",
       " 'brown': 4259,\n",
       " 'selling': 21442,\n",
       " 'novel': 16841,\n",
       " 'directed': 7609,\n",
       " 'ron': 20681,\n",
       " 'howard': 12125,\n",
       " 'stars': 22837,\n",
       " 'tom': 24337,\n",
       " 'hanks': 11427,\n",
       " 'cracking': 6487,\n",
       " 'partner': 17698,\n",
       " 'various': 25471,\n",
       " 'newspapers': 16618,\n",
       " 'currently': 6734,\n",
       " 'starring': 22836,\n",
       " 'long': 14704,\n",
       " 'engagement': 8764,\n",
       " 'jean': 13345,\n",
       " 'pierre': 18160,\n",
       " 'jeunet': 13393,\n",
       " 'responsible': 20251,\n",
       " 'directing': 7610,\n",
       " '2001': 429,\n",
       " 'starred': 22835,\n",
       " 'role': 20656,\n",
       " 'critically': 6589,\n",
       " 'acclaimed': 1452,\n",
       " 'dirty': 7625,\n",
       " 'pretty': 18763,\n",
       " 'oscar': 17263,\n",
       " 'preferring': 18674,\n",
       " 'name': 16391,\n",
       " 'hollywood': 11965,\n",
       " 'kate': 13661,\n",
       " 'beckinsale': 3320,\n",
       " 'widely': 26191,\n",
       " 'tipped': 24282,\n",
       " 'possibility': 18538,\n",
       " 'alongside': 2012,\n",
       " 'vanessa': 25453,\n",
       " 'paradis': 17622,\n",
       " 'juliette': 13556,\n",
       " 'binoche': 3611,\n",
       " 'thriller': 24165,\n",
       " 'upon': 25313,\n",
       " '17': 249,\n",
       " 'centred': 4953,\n",
       " 'global': 10846,\n",
       " 'conspiracy': 6083,\n",
       " 'surrounding': 23464,\n",
       " ...}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 1 and explained variance = 0.8302335701200946\n",
      "Number of components = 2 and explained variance = 0.9165093632208314\n",
      "Number of components = 4 and explained variance = 0.9291569440678306\n",
      "Number of components = 5 and explained variance = 0.9344860554115801\n",
      "Number of components = 10 and explained variance = 0.9477460316797051\n",
      "Number of components = 15 and explained variance = 0.9529730120135865\n",
      "Number of components = 20 and explained variance = 0.9560370191126828\n",
      "Number of components = 50 and explained variance = 0.9645716958622752\n",
      "Number of components = 100 and explained variance = 0.9711054139797324\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_comp = [1, 2, 4, 5, 10, 15, 20, 50, 100] # list containing different values of components\n",
    "\n",
    "explained = [] # explained variance ratio for each component of Truncated SVD\n",
    "\n",
    "for x in n_comp:\n",
    "    svd = TruncatedSVD(n_components=x, random_state=321)\n",
    "    svd.fit(Xc)\n",
    "    explained.append(svd.explained_variance_ratio_.sum())\n",
    "    print(\"Number of components = %r and explained variance = %r\"%(x,svd.explained_variance_ratio_.sum()))\n",
    "\n",
    "plt.plot(n_comp, explained)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.title(\"Plot of Number of components v/s explained variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many components are needed to explain at least 95% of the variance?\n",
    "\n",
    "Based on the selected values, it seems 15 components are needed to explain **95%** of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use these components and train a SVM model on the BBC dataset. \n",
    "Make a pipeline for your model. Compare your results on the test set with the previous pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('feature_selection', TruncatedSVD(n_components=15, random_state=321)),\n",
    "    ('classification', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('feature_extraction', TfidfTransformer()),\n",
       "                ('feature_selection',\n",
       "                 TruncatedSVD(n_components=15, random_state=321)),\n",
       "                ('classification', LinearSVC())])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.91      0.92      0.92        92\n",
      "entertainment       1.00      0.94      0.97        84\n",
      "     politics       0.91      0.92      0.92        77\n",
      "        sport       0.99      1.00      1.00       111\n",
      "         tech       0.94      0.96      0.95        81\n",
      "\n",
      "     accuracy                           0.95       445\n",
      "    macro avg       0.95      0.95      0.95       445\n",
      " weighted avg       0.95      0.95      0.95       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred6 = clf6.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred6, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the accuracy of the 6 pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# accuracy of each pipeline\n",
    "accuracies = [0.97, 0.95, 0.72, 0.94, 0.97, 0.95]\n",
    "pipeline_names = ['clf1', 'clf2', 'clf3', 'clf4', 'clf5', 'clf6']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(pipeline_names, accuracies, color='skyblue')\n",
    "plt.xlabel('Pipeline')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracies of the 6 Pipelines')\n",
    "plt.ylim([0.60, 1])\n",
    "for i, v in enumerate(accuracies):\n",
    "    plt.text(i, v + 0.01, str(v), ha='center', va='bottom')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
