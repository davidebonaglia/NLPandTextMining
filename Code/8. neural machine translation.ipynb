{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import statistics\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"/Users/davidebonaglia/Dropbox/PhD NOTES/COURSES/Utretch Summer School/Thursday/nld-eng/nld.txt\")\n",
    "nld_eng = to_lines(data)\n",
    "nld_eng = array(nld_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The string before translating is : text mining\n",
      "The string after translating is : woow dining\n"
     ]
    }
   ],
   "source": [
    "### Here you see an example on how to use the maketrans() function ###\n",
    "# specify the list of characters that need to be replaced\n",
    "str1 = \"mtex\"\n",
    "\n",
    "# specify the list of characters with which the characters need to be replaced\n",
    "str2 = \"dwoo\"\n",
    "\n",
    "# specify the list of characters that needs to be deleted\n",
    "str3 = \"u\"\n",
    "\n",
    "# target string \n",
    "temp_str = \"text mining\"\n",
    "\n",
    "# using maketrans() to construct a translate table\n",
    "table = temp_str.maketrans(str1, str2, str3)\n",
    "  \n",
    "# Printing original string \n",
    "print (\"The string before translating is : \", end =\"\")\n",
    "print (temp_str)\n",
    "  \n",
    "# using translate() to make translations.\n",
    "print (\"The string after translating is : \", end =\"\")\n",
    "print (temp_str.translate(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nld_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in nld_eng[:,0]]\n",
    "nld_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in nld_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(nld_eng)):\n",
    "    nld_eng[i,0] = nld_eng[i,0].lower()    \n",
    "    nld_eng[i,1] = nld_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['go', 'lopen',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #7764436 (LinguisticFusion)'],\n",
       "       ['go', 'vooruit',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #7915821 (Elsofie)'],\n",
       "       ['hi', 'hoi',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #537889 (Dorenda)'],\n",
       "       ...,\n",
       "       ['always use distilled water in steam irons because using ordinary water will cause a mineral buildup over time that will clog the steam holes',\n",
       "        'gebruik altijd gedistilleerd water in stoomstrijkijzers want gewoon water zorgt voor mineraalophoping dat de stoomgaatjes na verloop van tijd verstopt',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #3020388 (Delian) & #3037091 (Citrine)'],\n",
       "       ['if you translate from your second language into your own native language rather than the other way around youre less likely to make mistakes',\n",
       "        'als je vanuit je tweede taal naar je eigen moedertaal vertaalt in plaats van andersom maak je minder snel fouten',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1230823 (CK) & #8627687 (MarijnKp)'],\n",
       "       ['if someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker in other words you dont really sound like a native speaker',\n",
       "        'als iemand die je achtergrond niet kent zegt dat je klinkt als een moedertaalspreker betekent dat dat diegene waarschijnlijk iets in je spreken opgemerkt heeft dat hem deed realiseren dat je geen moedertaalspreker bent met andere woorden je klinkt niet echt als een moedertaalspreker',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #1056762 (ReneeMona)']],\n",
       "      dtype='<U286')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nld_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "nld_l = []\n",
    "# populate the lists with sentence lengths\n",
    "for i in nld_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in nld_eng[:,1]:\n",
    "    nld_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df = pd.DataFrame({'eng':eng_l, 'nld':nld_l})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(nld_eng, test_size=0.2, random_state=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 9073\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = Tokenizer()\n",
    "eng_tokenizer.fit_on_texts(nld_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dutch Vocabulary Size: 12794\n"
     ]
    }
   ],
   "source": [
    "# prepare Dutch tokenizer\n",
    "nld_tokenizer = Tokenizer()\n",
    "nld_tokenizer.fit_on_texts(nld_eng[:, 1])\n",
    "nld_vocab_size = len(nld_tokenizer.word_index) + 1\n",
    "print('Dutch Vocabulary Size: %d' % nld_vocab_size)\n",
    "# print('Dutch Vocabulary Size:', nld_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, maximum_length, sentences):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(sentences)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=maximum_length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_length = 40\n",
    "nld_length = 40\n",
    "# prepare training data\n",
    "train_X = encode_sequences(nld_tokenizer, nld_length, train[:, 1])\n",
    "train_Y = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data\n",
    "test_X = encode_sequences(nld_tokenizer, nld_length, test[:, 1])\n",
    "test_Y = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, embedding_size, LSTMunits):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, embedding_size, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(LSTMunits))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(LSTMunits, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(nld_vocab_size, \n",
    "                    eng_vocab_size, \n",
    "                    nld_length, \n",
    "                    eng_length, \n",
    "                    300, \n",
    "                    512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 300)           3838200   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 512)               1665024   \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 40, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 40, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40, 9073)          4654449   \n",
      "=================================================================\n",
      "Total params: 12,256,873\n",
      "Trainable params: 12,256,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " 34/275 [==>...........................] - ETA: 10:27 - loss: 1.8046 - accuracy: 0.8358"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-453d01df4553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                              mode='min')\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m history = model.fit(train_X, train_Y.reshape(train_Y.shape[0], train_Y.shape[1], 1),\n\u001b[0m\u001b[1;32m      9\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filename = 'model.15Epochs'\n",
    "checkpoint = ModelCheckpoint(filename, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')\n",
    "\n",
    "history = model.fit(train_X, train_Y.reshape(train_Y.shape[0], train_Y.shape[1], 1),\n",
    "                    epochs=15,\n",
    "                    batch_size=128, \n",
    "                    validation_split = 0.2,\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
