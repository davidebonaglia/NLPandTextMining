{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Sentiment classification with sklearn\n",
    "\n",
    "Data: **Book reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string \n",
    "import nltk\n",
    "import gensim\n",
    "import spacy\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_no</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>id</th>\n",
       "      <th>age_category</th>\n",
       "      <th>book_genre</th>\n",
       "      <th>rating_no.1</th>\n",
       "      <th>tokenised_text</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>284434</td>\n",
       "      <td>review_244526687</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Popular fiction - general</td>\n",
       "      <td>1.0</td>\n",
       "      <td>like adult book concept simply ya spoiler exam...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30788</td>\n",
       "      <td>review_528067373</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>okay read college maybe little biased rating l...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>84989</td>\n",
       "      <td>review_3210428778</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>remember read book club hating probably chance...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>61511</td>\n",
       "      <td>review_112612281</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yeah star cause know like make like plus depre...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>112948</td>\n",
       "      <td>review_380001099</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assign book brit lit class read email teacher ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>5.0</td>\n",
       "      <td>196479</td>\n",
       "      <td>review_794912077</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>5.0</td>\n",
       "      <td>great rush anger wash clean empty hope gaze da...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6914</td>\n",
       "      <td>review_3223306470</td>\n",
       "      <td>Young adult</td>\n",
       "      <td>Popular fiction - general</td>\n",
       "      <td>5.0</td>\n",
       "      <td>book boy facial deformity start school time ag...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5.0</td>\n",
       "      <td>63008</td>\n",
       "      <td>review_589976720</td>\n",
       "      <td>Young adult</td>\n",
       "      <td>Popular fiction - general</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fault stars book girl name boy name thyroid or...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5.0</td>\n",
       "      <td>268251</td>\n",
       "      <td>review_1519621576</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Non fiction</td>\n",
       "      <td>5.0</td>\n",
       "      <td>find book exciting interesting think great tim...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5.0</td>\n",
       "      <td>273757</td>\n",
       "      <td>review_1992170267</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Non fiction</td>\n",
       "      <td>5.0</td>\n",
       "      <td>devastating read know real clear voice humaniz...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating_no  Unnamed: 1                 id age_category  \\\n",
       "0           1.0      284434   review_244526687        Adult   \n",
       "1           1.0       30788   review_528067373        Adult   \n",
       "2           1.0       84989  review_3210428778        Adult   \n",
       "3           1.0       61511   review_112612281        Adult   \n",
       "4           1.0      112948   review_380001099        Adult   \n",
       "...         ...         ...                ...          ...   \n",
       "9995        5.0      196479   review_794912077        Adult   \n",
       "9996        5.0        6914  review_3223306470  Young adult   \n",
       "9997        5.0       63008   review_589976720  Young adult   \n",
       "9998        5.0      268251  review_1519621576        Adult   \n",
       "9999        5.0      273757  review_1992170267        Adult   \n",
       "\n",
       "                     book_genre  rating_no.1  \\\n",
       "0     Popular fiction - general          1.0   \n",
       "1              Literary fiction          1.0   \n",
       "2              Literary fiction          1.0   \n",
       "3              Literary fiction          1.0   \n",
       "4              Literary fiction          1.0   \n",
       "...                         ...          ...   \n",
       "9995           Literary fiction          5.0   \n",
       "9996  Popular fiction - general          5.0   \n",
       "9997  Popular fiction - general          5.0   \n",
       "9998                Non fiction          5.0   \n",
       "9999                Non fiction          5.0   \n",
       "\n",
       "                                         tokenised_text  n_tokens  \n",
       "0     like adult book concept simply ya spoiler exam...        30  \n",
       "1     okay read college maybe little biased rating l...        21  \n",
       "2     remember read book club hating probably chance...        18  \n",
       "3     yeah star cause know like make like plus depre...        13  \n",
       "4     assign book brit lit class read email teacher ...        22  \n",
       "...                                                 ...       ...  \n",
       "9995  great rush anger wash clean empty hope gaze da...        25  \n",
       "9996  book boy facial deformity start school time ag...        37  \n",
       "9997  fault stars book girl name boy name thyroid or...        46  \n",
       "9998  find book exciting interesting think great tim...        23  \n",
       "9999  devastating read know real clear voice humaniz...        23  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/davidebonaglia/Dropbox/PhD NOTES/COURSES/Utretch Summer School/Monday/book_reviews.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Document-term matrix. \n",
    "\n",
    "The **CountVectorizer** class counts **how often each word occurs in each document**: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "Optionally, we can also pass ngram_range as a parameter to see if combinations of multiple words are better predictors for ratings. \n",
    "\n",
    "We define the output of the fit_transform function on 'tokenised_text' as your feature matrix X, and the star ratings ('rating_no') as the variable y you're trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# with the ngram_range option:\n",
    "# vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "X = vectorizer.fit_transform(data['tokenised_text'])\n",
    "y = data['rating_no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect the words in the document-term matrix, we can use get_feature_names() on the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aaaaaaa', 'aaaaaaaahhhhh', 'aaaaah', 'aaaaand', 'aaaahhhhh', 'aaack', 'aaah', 'aaarrrgggh', 'aagggh', 'aaj', 'ab', 'aback', 'abacus', 'abandon', 'abandone', 'abandoned', 'abandonment', 'abasement', 'abasment']\n"
     ]
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "print(words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could also use a **TfidfVectorizer**: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
    "\n",
    "This class counts **how often a word occurs in a document and weighs it against how often the word occurs in the whole corpus**. This is a way to eliminate words that are frequent but not very meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer2 = TfidfVectorizer()\n",
    "X = vectorizer2.fit_transform(data['tokenised_text'])\n",
    "y = data['rating_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aaaaaaa', 'aaaaaaaahhhhh', 'aaaaah', 'aaaaand', 'aaaahhhhh', 'aaack', 'aaah', 'aaarrrgggh', 'aagggh', 'aaj', 'ab', 'aback', 'abacus', 'abandon', 'abandone', 'abandoned', 'abandonment', 'abasement', 'abasment']\n"
     ]
    }
   ],
   "source": [
    "words2 = vectorizer2.get_feature_names()\n",
    "print(words2[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test data sets\n",
    "\n",
    "After defining your document-term matrix, we can split the data into train- and test sets. \n",
    "\n",
    "Note that random_state is used so that the split will be the same for everyone in the group, such that different random selections don't cause slightly different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will test different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.416969696969697"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression(max_iter=3000)\n",
    "model = logistic.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with 3 neighbours: 0.2887878787878788 \n",
      "accuracy with 10 neighbours: 0.32484848484848483 \n",
      "accuracy with 100 neighbours: 0.3842424242424242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "model = knn.fit(X_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "model2 = knn.fit(X_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=100)\n",
    "model3 = knn.fit(X_train, y_train)\n",
    "print('accuracy with 3 neighbours:', model.score(X_test, y_test),\n",
    "      '\\naccuracy with 10 neighbours:', model2.score(X_test, y_test), \n",
    "      '\\naccuracy with 100 neighbours:', model3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multionimal Naive Bayes\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with alpha=1: 0.4121212121212121 \n",
      "accuracy with alpha=10: 0.40393939393939393 \n",
      "accuracy with alpha=100: 0.353030303030303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=1)\n",
    "model = nb.fit(X_train, y_train)\n",
    "\n",
    "nb = MultinomialNB(alpha=10)\n",
    "model2 = nb.fit(X_train, y_train)\n",
    "\n",
    "nb = MultinomialNB(alpha=100)\n",
    "model3 = nb.fit(X_train, y_train)\n",
    "print('accuracy with alpha=1:', model.score(X_test, y_test),\n",
    "      '\\naccuracy with alpha=10:', model2.score(X_test, y_test),\n",
    "      '\\naccuracy with alpha=100:', model3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with default regularization: 0.38303030303030305 \n",
      "accuracy with more regularization: 0.4175757575757576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(C=1.0)\n",
    "model = svm.fit(X_train, y_train)\n",
    "\n",
    "svm = LinearSVC(C=0.1)\n",
    "model2 = svm.fit(X_train, y_train)\n",
    "print('accuracy with default regularization:', model.score(X_test, y_test), \n",
    "      '\\naccuracy with more regularization:', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with maximum tree depth 5: 0.26212121212121214 \n",
      "accuracy with unlimited tree depth: 0.2821212121212121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "model = tree.fit(X_train, y_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=None)\n",
    "model2 = tree.fit(X_train, y_train)\n",
    "print('accuracy with maximum tree depth 5:', model.score(X_test, y_test), \n",
    "      '\\naccuracy with unlimited tree depth:', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with 3 trees: 0.2642424242424242 \n",
      "accuracy with 20 trees: 0.32575757575757575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=3)\n",
    "model = rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=20)\n",
    "model2 = rfc.fit(X_train, y_train)\n",
    "print('accuracy with 3 trees:', model.score(X_test, y_test), \n",
    "      '\\naccuracy with 20 trees:', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the parameters which lead to best results\n",
    "\n",
    "GridSearch allows to automatate this process\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best score achieved: 0.336969696969697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv': None,\n",
       " 'error_score': nan,\n",
       " 'estimator__algorithm': 'auto',\n",
       " 'estimator__leaf_size': 30,\n",
       " 'estimator__metric': 'minkowski',\n",
       " 'estimator__metric_params': None,\n",
       " 'estimator__n_jobs': None,\n",
       " 'estimator__n_neighbors': 5,\n",
       " 'estimator__p': 2,\n",
       " 'estimator__weights': 'uniform',\n",
       " 'estimator': KNeighborsClassifier(),\n",
       " 'iid': 'deprecated',\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'n_neighbors': [2, 20]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#parameters = {'n_estimators': [2,20]}\n",
    "#knn = RandomForestClassifier()\n",
    "\n",
    "parameters = {'n_neighbors': [2,20]}\n",
    "knn = KNeighborsClassifier()\n",
    "search = GridSearchCV(knn, parameters)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print('the best score achieved:', search.score(X_test, y_test))\n",
    "\n",
    "# get_params() gives the parameters leading to this best score (in 'estimator')\n",
    "search.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining it with other classifiers (for instance with a Voting Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37696969696969695"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vc = VotingClassifier(estimators=[('knn', knn), ('nb', nb), ('svm', svm), ('tree', tree)])\n",
    "vc.fit(X_train, y_train)\n",
    "vc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "\n",
    "testing sentiment analysis using the tranformers library available at: https://huggingface.co/docs/transformers/quicktour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and use the **nlptown/bert-base-multilingual-uncased-sentiment** model from nlptown, apply it to the first 100 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9dc926fb4f40159553cbfb6100a0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=669729124.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6203ca8edc974c3899b8c8b3fd2fba1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6e537e21fd45de8aa120d945599513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=871891.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0485d8a2e6274dc89f72543b729e24c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-ff20f9c146da>:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out_df = out_df.append(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "out_df = pd.DataFrame()\n",
    "\n",
    "for i, row in data.head(100).iterrows():\n",
    "    prediction = classifier(row['tokenised_text'][:512])\n",
    "    label = int(prediction[0]['label'].split(' ')[0])\n",
    "    df = pd.DataFrame({'predicted_rating': [label],'star_rating': [int(row['rating_no'])]})\n",
    "    out_df = out_df.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the predictions against the star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage correct predictions: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('percentage correct predictions:', len(out_df[out_df['predicted_rating']==out_df['star_rating']])/100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
