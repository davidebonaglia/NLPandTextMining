{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Practical 2: Sentiment classification with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_no</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>id</th>\n",
       "      <th>age_category</th>\n",
       "      <th>book_genre</th>\n",
       "      <th>rating_no.1</th>\n",
       "      <th>tokenised_text</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>284434</td>\n",
       "      <td>review_244526687</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Popular fiction - general</td>\n",
       "      <td>1.0</td>\n",
       "      <td>like adult book concept simply ya spoiler exam...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30788</td>\n",
       "      <td>review_528067373</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>okay read college maybe little biased rating l...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>84989</td>\n",
       "      <td>review_3210428778</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>remember read book club hating probably chance...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>61511</td>\n",
       "      <td>review_112612281</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yeah star cause know like make like plus depre...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>112948</td>\n",
       "      <td>review_380001099</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assign book brit lit class read email teacher ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>5.0</td>\n",
       "      <td>196479</td>\n",
       "      <td>review_794912077</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Literary fiction</td>\n",
       "      <td>5.0</td>\n",
       "      <td>great rush anger wash clean empty hope gaze da...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6914</td>\n",
       "      <td>review_3223306470</td>\n",
       "      <td>Young adult</td>\n",
       "      <td>Popular fiction - general</td>\n",
       "      <td>5.0</td>\n",
       "      <td>book boy facial deformity start school time ag...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>5.0</td>\n",
       "      <td>63008</td>\n",
       "      <td>review_589976720</td>\n",
       "      <td>Young adult</td>\n",
       "      <td>Popular fiction - general</td>\n",
       "      <td>5.0</td>\n",
       "      <td>fault stars book girl name boy name thyroid or...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5.0</td>\n",
       "      <td>268251</td>\n",
       "      <td>review_1519621576</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Non fiction</td>\n",
       "      <td>5.0</td>\n",
       "      <td>find book exciting interesting think great tim...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5.0</td>\n",
       "      <td>273757</td>\n",
       "      <td>review_1992170267</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Non fiction</td>\n",
       "      <td>5.0</td>\n",
       "      <td>devastating read know real clear voice humaniz...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating_no  Unnamed: 1                 id age_category  \\\n",
       "0           1.0      284434   review_244526687        Adult   \n",
       "1           1.0       30788   review_528067373        Adult   \n",
       "2           1.0       84989  review_3210428778        Adult   \n",
       "3           1.0       61511   review_112612281        Adult   \n",
       "4           1.0      112948   review_380001099        Adult   \n",
       "...         ...         ...                ...          ...   \n",
       "9995        5.0      196479   review_794912077        Adult   \n",
       "9996        5.0        6914  review_3223306470  Young adult   \n",
       "9997        5.0       63008   review_589976720  Young adult   \n",
       "9998        5.0      268251  review_1519621576        Adult   \n",
       "9999        5.0      273757  review_1992170267        Adult   \n",
       "\n",
       "                     book_genre  rating_no.1  \\\n",
       "0     Popular fiction - general          1.0   \n",
       "1              Literary fiction          1.0   \n",
       "2              Literary fiction          1.0   \n",
       "3              Literary fiction          1.0   \n",
       "4              Literary fiction          1.0   \n",
       "...                         ...          ...   \n",
       "9995           Literary fiction          5.0   \n",
       "9996  Popular fiction - general          5.0   \n",
       "9997  Popular fiction - general          5.0   \n",
       "9998                Non fiction          5.0   \n",
       "9999                Non fiction          5.0   \n",
       "\n",
       "                                         tokenised_text  n_tokens  \n",
       "0     like adult book concept simply ya spoiler exam...        30  \n",
       "1     okay read college maybe little biased rating l...        21  \n",
       "2     remember read book club hating probably chance...        18  \n",
       "3     yeah star cause know like make like plus depre...        13  \n",
       "4     assign book brit lit class read email teacher ...        22  \n",
       "...                                                 ...       ...  \n",
       "9995  great rush anger wash clean empty hope gaze da...        25  \n",
       "9996  book boy facial deformity start school time ag...        37  \n",
       "9997  fault stars book girl name boy name thyroid or...        46  \n",
       "9998  find book exciting interesting think great tim...        23  \n",
       "9999  devastating read know real clear voice humaniz...        23  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string \n",
    "import nltk\n",
    "import gensim\n",
    "import spacy\n",
    "\n",
    "import pandas as pd \n",
    "data = pd.read_csv(\"/Users/davidebonaglia/Dropbox/PhD NOTES/COURSES/Utretch Summer School/Monday/book_reviews.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now you can construct the document-term matrix. \n",
    "# The CountVectorizer class counts how often each word occurs in each document. \n",
    "# Optionally, you can also pass ngram_range as a parameter, to see if combinations of multiple words are better predictors for ratings. \n",
    "\n",
    "# Define the output of the fit_transform function on 'tokenised_text' as your feature matrix X, \n",
    "# and the star ratings ('rating_no') as the variable y you're trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "# vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "X = vectorizer.fit_transform(data['tokenised_text'])\n",
    "y = data['rating_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aaaaaaa', 'aaaaaaaahhhhh', 'aaaaah', 'aaaaand', 'aaaahhhhh', 'aaack', 'aaah', 'aaarrrgggh', 'aagggh', 'aaj', 'ab', 'aback', 'abacus', 'abandon', 'abandone', 'abandoned', 'abandonment', 'abasement', 'abasment']\n"
     ]
    }
   ],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "print(words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternatively, you could also use a TfidfVectorizer: \n",
    "#this class counts how often a word occurs in a document and weighs it against how often the word occurs \n",
    "#in the whole corpus. \n",
    "#This is a way to eliminate words that are frequent but not very meaningful. \n",
    "\n",
    "#You can play around with different vectorizers to see how they affect your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer2 = TfidfVectorizer()\n",
    "X = vectorizer2.fit_transform(data['tokenised_text'])\n",
    "y = data['rating_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aaaaaaa', 'aaaaaaaahhhhh', 'aaaaah', 'aaaaand', 'aaaahhhhh', 'aaack', 'aaah', 'aaarrrgggh', 'aagggh', 'aaj', 'ab', 'aback', 'abacus', 'abandon', 'abandone', 'abandoned', 'abandonment', 'abasement', 'abasment']\n"
     ]
    }
   ],
   "source": [
    "words2 = vectorizer2.get_feature_names()\n",
    "print(words2[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After defining your document-term matrix, you can split the data into train- and test sets. \n",
    "\n",
    "#Note that random_state is used so that the split will be the same for everyone in the group, \n",
    "#such that different random selections don't cause slightly different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.416969696969697"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0. Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression(max_iter=3000)\n",
    "model = logistic.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with 3 neighbours: 0.2887878787878788 \n",
      "accuracy with 10 neighbours: 0.32484848484848483 \n",
      "accuracy with 100 neighbours: 0.3842424242424242\n"
     ]
    }
   ],
   "source": [
    "#1. K-Nearest Neighbor classifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "model = knn.fit(X_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "model2 = knn.fit(X_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=100)\n",
    "model3 = knn.fit(X_train, y_train)\n",
    "print('accuracy with 3 neighbours:', model.score(X_test, y_test),\n",
    "      '\\naccuracy with 10 neighbours:', model2.score(X_test, y_test), \n",
    "      '\\naccuracy with 100 neighbours:', model3.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with alpha=1: 0.4121212121212121 \n",
      "accuracy with alpha=10: 0.40393939393939393\n"
     ]
    }
   ],
   "source": [
    "#2. Multionimal Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=1)\n",
    "model = nb.fit(X_train, y_train)\n",
    "\n",
    "nb = MultinomialNB(alpha=10)\n",
    "model2 = nb.fit(X_train, y_train)\n",
    "print('accuracy with alpha=1:', model.score(X_test, y_test),\n",
    "      '\\naccuracy with alpha=10:', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with default regularization: 0.38303030303030305 \n",
      "accuracy with more regularization: 0.4175757575757576\n"
     ]
    }
   ],
   "source": [
    "#3. Support Vector Machine\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(C=1.0)\n",
    "model = svm.fit(X_train, y_train)\n",
    "\n",
    "svm = LinearSVC(C=0.1)\n",
    "model2 = svm.fit(X_train, y_train)\n",
    "print('accuracy with default regularization:', model.score(X_test, y_test), \n",
    "      '\\naccuracy with more regularization:', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with maximum tree depth 5: 0.26212121212121214 \n",
      "accuracy with unlimited tree depth: 0.2866666666666667\n"
     ]
    }
   ],
   "source": [
    "#4. Decision Tree Classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "model = tree.fit(X_train, y_train)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=None)\n",
    "model2 = tree.fit(X_train, y_train)\n",
    "print('accuracy with maximum tree depth 5:', model.score(X_test, y_test), \n",
    "      '\\naccuracy with unlimited tree depth:', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with 3 trees: 0.2687878787878788 \n",
      "accuracy with 20 trees: 0.3336363636363636\n"
     ]
    }
   ],
   "source": [
    "#5. Random Forest Classifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=3)\n",
    "model = rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=20)\n",
    "model2 = rfc.fit(X_train, y_train)\n",
    "print('accuracy with 3 trees:', model.score(X_test, y_test), \n",
    "      '\\naccuracy with 20 trees:', model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the parameters which lead to best results. You can also automatate this with GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best score achieved: 0.336969696969697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv': None,\n",
       " 'error_score': nan,\n",
       " 'estimator__algorithm': 'auto',\n",
       " 'estimator__leaf_size': 30,\n",
       " 'estimator__metric': 'minkowski',\n",
       " 'estimator__metric_params': None,\n",
       " 'estimator__n_jobs': None,\n",
       " 'estimator__n_neighbors': 5,\n",
       " 'estimator__p': 2,\n",
       " 'estimator__weights': 'uniform',\n",
       " 'estimator': KNeighborsClassifier(),\n",
       " 'iid': 'deprecated',\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'n_neighbors': [2, 20]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# set the search space for grid search. In this case, between 2 and 20 nearest neighbors\n",
    "#parameters = {'n_estimators': [2,20]}\n",
    "#knn = RandomForestClassifier()\n",
    "\n",
    "parameters = {'n_neighbors': [2,20]}\n",
    "knn = KNeighborsClassifier()\n",
    "search = GridSearchCV(knn, parameters)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# the best score achieved\n",
    "print('the best score achieved:', search.score(X_test, y_test))\n",
    "\n",
    "# get_params() gives the parameters leading to this best score (in 'estimator')\n",
    "search.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try combining multiple classifiers, for instance with a Voting Classifier Can you get a better result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3942424242424242"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vc = VotingClassifier(estimators=[('knn', knn), ('nb', nb), ('svm', svm), ('tree', tree)])\n",
    "vc.fit(X_train, y_train)\n",
    "vc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment analysis with transformers library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404 Client Error: Not Found for url: https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/tf_model.h5\n",
      "404 Client Error: Not Found for url: https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/tf_model.h5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model nlptown/bert-base-multilingual-uncased-sentiment with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'>).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0daf276a17d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentiment-analysis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nlptown/bert-base-multilingual-uncased-sentiment\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;31m# Will load the correct model if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mmodel_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtargeted_task\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     framework, model = infer_framework_load_model(\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mmodel_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not load model {model} with any of the following classes: {class_tuple}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mframework\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"tf\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TF\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not load model nlptown/bert-base-multilingual-uncased-sentiment with any of the following classes: (<class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'>)."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "out_df = pd.DataFrame()\n",
    "for i, row in data.head(100).iterrows():\n",
    "    prediction = classifier(row['tokenised_text'][:512])\n",
    "    label = int(prediction[0]['label'].split(' ')[0])\n",
    "    df = pd.DataFrame({'predicted_rating': [label],\n",
    "                    'star_rating': [int(row['rating_no'])]})\n",
    "    out_df = out_df.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('percentage correct predictions:', len(out_df[out_df['predicted_rating']==out_df['star_rating']])/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
